#Network Section : Network
[Model]
Type = NeuralNetwork	# Network Type : Regression, KNN, NeuralNetwork
Learning_rate = 0.0001 	# Learning Rate
Decay_rate = 0.96	# for the decay_rate for the decayed learning rate
Decay_steps = 1000       # decay step for the exponential decayed learning rate
Epochs = 30000		# Epochs
Optimizer = adam 	# Optimizer : sgd (stochastic gradien decent),
                        #             adam(Adamtive Moment Estimation)
Loss = cross  		# Loss function : mse (mean squared error)
                        #                 cross(cross entropy)
Save_Path = "model_cls.bin"  	# model path to save / read
batch_size = 32		# batch size
beta1 = 0.9 		# beta 1 for adam
beta2 = 0.9999	# beta 2 for adam
epsilon = 1e-7	# epsilon for adam

[DataSet]
BufferSize=100
TrainData="trainingSet.dat"
ValidData="trainingSet.dat"
LabelData="label.dat"

[input_ini]
backbone = "model.ini"
Input_Shape = 1:28:28

[fclayer]
Type = fully_connected
input_layers = input_ini
Unit = 10		# Output Layer Dimension ( = Weight Width )
Bias_initializer = zeros
Activation = softmax 	# activation : sigmoid, softmax
Weight_Decay = l2norm
weight_Decay_Lambda = 0.005
trainable = true

[output_layer]
Type = fully_connected
input_layers = fclayer
Unit = 10		# Output Layer Dimension ( = Weight Width )

